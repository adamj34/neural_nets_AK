{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "str_to_inx = {str:inx for inx, str in enumerate(chars, start=1)}\n",
    "str_to_inx['.'] = 0\n",
    "inx_to_str = {inx:str for inx, str in str_to_inx.items()}\n",
    "str_to_inx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "X, Y = [], []\n",
    "for word in words[:5]:\n",
    "    word = block_size * '.' + word + '.'\n",
    "    # for ch1, ch2, ch3, ch4 in zip(word, word[1:], word[2:], word[3:]):\n",
    "    #     # print(''.join([ch1, ch2, ch3]), '=>', ch4)\n",
    "    #     X.append([str_to_inx[ch] for ch in [ch1, ch2, ch3]])\n",
    "    #     Y.append(str_to_inx[ch4])\n",
    "    end_inx = block_size\n",
    "    for start_inx, char in enumerate(word[block_size:]):\n",
    "        X.append([str_to_inx[ch] for ch in word[start_inx:end_inx]])\n",
    "        Y.append(str_to_inx[char])\n",
    "        end_inx += 1\n",
    "\n",
    "\n",
    "X, Y = torch.tensor(X), torch.tensor(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.Size([32, 3]), torch.int64, torch.Size([32]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype, X.shape, Y.dtype, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1071, -1.0641],\n",
       "        [-1.4979,  0.0274],\n",
       "        [-0.8261, -1.0237],\n",
       "        [-0.1853, -1.2831],\n",
       "        [-1.0521,  0.2812],\n",
       "        [-0.3013, -1.3081],\n",
       "        [ 1.0218, -0.6376],\n",
       "        [ 0.1985, -0.5644],\n",
       "        [-0.5787,  0.2149],\n",
       "        [-1.0239, -0.5308],\n",
       "        [-0.2686,  0.4993],\n",
       "        [-1.4395, -0.2274],\n",
       "        [-0.4591, -0.2764],\n",
       "        [ 1.1824,  0.3577],\n",
       "        [-1.1010, -1.7622]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 2))\n",
    "C[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [-0.3013, -1.3081]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.3013, -1.3081],\n",
       "         [ 1.1824,  0.3577]],\n",
       "\n",
       "        [[-0.3013, -1.3081],\n",
       "         [ 1.1824,  0.3577],\n",
       "         [ 1.1824,  0.3577]],\n",
       "\n",
       "        [[ 1.1824,  0.3577],\n",
       "         [ 1.1824,  0.3577],\n",
       "         [-1.4979,  0.0274]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [ 0.5842, -0.0817]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [ 0.5842, -0.0817],\n",
       "         [-0.4591, -0.2764]],\n",
       "\n",
       "        [[ 0.5842, -0.0817],\n",
       "         [-0.4591, -0.2764],\n",
       "         [-1.0239, -0.5308]],\n",
       "\n",
       "        [[-0.4591, -0.2764],\n",
       "         [-1.0239, -0.5308],\n",
       "         [-0.3372, -0.1407]],\n",
       "\n",
       "        [[-1.0239, -0.5308],\n",
       "         [-0.3372, -0.1407],\n",
       "         [-1.0239, -0.5308]],\n",
       "\n",
       "        [[-0.3372, -0.1407],\n",
       "         [-1.0239, -0.5308],\n",
       "         [-1.4979,  0.0274]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [-1.4979,  0.0274]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-1.4979,  0.0274],\n",
       "         [-0.3372, -0.1407]],\n",
       "\n",
       "        [[-1.4979,  0.0274],\n",
       "         [-0.3372, -0.1407],\n",
       "         [-1.4979,  0.0274]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [-1.0239, -0.5308]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-1.0239, -0.5308],\n",
       "         [ 0.2648,  1.1647]],\n",
       "\n",
       "        [[-1.0239, -0.5308],\n",
       "         [ 0.2648,  1.1647],\n",
       "         [-1.4979,  0.0274]],\n",
       "\n",
       "        [[ 0.2648,  1.1647],\n",
       "         [-1.4979,  0.0274],\n",
       "         [-0.8261, -1.0237]],\n",
       "\n",
       "        [[-1.4979,  0.0274],\n",
       "         [-0.8261, -1.0237],\n",
       "         [-0.3013, -1.3081]],\n",
       "\n",
       "        [[-0.8261, -1.0237],\n",
       "         [-0.3013, -1.3081],\n",
       "         [-0.4591, -0.2764]],\n",
       "\n",
       "        [[-0.3013, -1.3081],\n",
       "         [-0.4591, -0.2764],\n",
       "         [-0.4591, -0.2764]],\n",
       "\n",
       "        [[-0.4591, -0.2764],\n",
       "         [-0.4591, -0.2764],\n",
       "         [-1.4979,  0.0274]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [-0.1071, -1.0641],\n",
       "         [ 0.2648,  1.1647]],\n",
       "\n",
       "        [[-0.1071, -1.0641],\n",
       "         [ 0.2648,  1.1647],\n",
       "         [ 0.5842, -0.0817]],\n",
       "\n",
       "        [[ 0.2648,  1.1647],\n",
       "         [ 0.5842, -0.0817],\n",
       "         [ 1.1146,  0.7134]],\n",
       "\n",
       "        [[ 0.5842, -0.0817],\n",
       "         [ 1.1146,  0.7134],\n",
       "         [-0.5787,  0.2149]],\n",
       "\n",
       "        [[ 1.1146,  0.7134],\n",
       "         [-0.5787,  0.2149],\n",
       "         [-1.0239, -0.5308]],\n",
       "\n",
       "        [[-0.5787,  0.2149],\n",
       "         [-1.0239, -0.5308],\n",
       "         [-1.4979,  0.0274]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden layer, # of inputs = 6 = 2 * 3 (to the neuron), # of neurons - a variable\n",
    "W1 = torch.randn((6, 100)) # 100 - neurons\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1), 1) == emb.view(emb.shape[0], 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(emb.shape[0], 6) == torch.cat([emb[:,0,:],emb[:,1,:],emb[:,2,:]],1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Most of the times Tanh function is usually used in hidden layers of a neural network because its values lies between -1 to 1 that’s why the mean for the hidden layer comes out be 0 or its very close to 0, hence tanh functions helps in centering the data by bringing mean close to 0 which makes learning for the next layer much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.tanh(emb.view(emb.shape[0], 6) @ W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn((27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.6457)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "loss = -probs[torch.arange(X.shape[0]), Y].log().mean()\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
